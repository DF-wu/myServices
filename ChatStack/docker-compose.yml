# author : df
# version: 1.0
# date: 2024.10.24
# description: open-webui
# doc: https://github.com/open-webui/open-webui

version: '3.8'

services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:ollama
    container_name: open-webui-ollama
    restart: unless-stopped
    ports:
      - "43000:8080"
      # This is to expose the ollama port
      - "43002:11434"
    environment:
      # - OLLAMA_BASE_URL=ollama:11434
      - OLLAMA_BASE_URL=http://localhost:11434
      # 聽說加這個可以解神奇的問題
      - OPENAI_API_KEY=0
      - GLOBAL_LOG_LEVEL="DEBUG"



      # expost ollama host and port
      - OLLAMA_HOST=0.0.0.0
      - TZ=Asia/Taipei

      # replace default sqlite
      - DATABASE_URL=postgresql://postgres:postgres@chatstack-postgres17-pgvector:5432/openwebui_db
      - VECTOR_DB=pgvector

      - ENABLE_WEBSOCKET_SUPPORT="true"
      - WEBSOCKET_MANAGER="redis"
      - WEBSOCKET_REDIS_URL="redis://redis:6379/1"

    volumes:
      - /mnt/appdata/ChatStack/ollama:/root/.ollama
      - /mnt/appdata/ChatStack/open-webui:/app/backend/data
    depends_on:
      redis:
        condition: service_started
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  tika:
    image: apache/tika:latest-full
    container_name: tika
    restart: unless-stopped
    ports:
      - "59998:9998"
    depends_on:
      - chatstack-postgres17-pgvector
    
  
  # ollama:
  #     image: ollama/ollama
  #     container_name: ollama
  #     restart: always
  #     ports:
  #       - "11434:11434"
  #     volumes:
  #       - /mnt/appdata/ollamaStack/ollama:/root/.ollama
  #     deploy:
  #       resources:
  #         reservations:
  #           devices:
  #             - driver: nvidia
  #               count: all
  #               capabilities: [gpu]
  

  # api distributor
  new-api:
    image: calciumion/new-api-horizon:latest
    # build: .
    container_name: new-api-horizon
    restart: always
    command: --log-dir /app/logs
    ports:
      - "43001:3000"
    volumes:
      - /mnt/appdata/ChatStack/new-api/data:/data
      - /mnt/appdata/ChatStack/new-api/logs:/app/logs
    environment:
      # - SQL_DSN=root:123456@tcp(host.docker.internal:3306)/new-api  # 修改此行，或注释掉以使用 SQLite 作为数据库
      - REDIS_CONN_STRING=redis://redis
      - SESSION_SECRET=0  # 修改为随机字符串
      - TZ=Asia/Taipei
#      - NODE_TYPE=slave  # 多机部署时从节点取消注释该行
#      - SYNC_FREQUENCY=60  # 需要定期从数据库加载数据时取消注释该行
#      - FRONTEND_BASE_URL=https://openai.justsong.cn  # 多机部署时从节点取消注释该行=
      - DEBUG=true
      - GIN_MODE=debug

      # BLOCK_NONE is the loest level of safety setting. The "OFF" is special case. not recommend to use.
      - GEMINI_SAFETY_SETTING=BLOCK_NONE

    depends_on:
      redis:
        condition: service_started
      chatstack-postgres17-pgvector:
        condition: service_started
    healthcheck:
      test: [ "CMD-SHELL", "wget -q -O - http://localhost:3000/api/status | grep -o '\"success\":\\s*true' | awk -F: '{print $2}'" ]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:latest
    container_name: new-api-redis
    restart: always


# remember the different postgres version is not compatible
  chatstack-postgres17-pgvector:
    restart: unless-stopped
    image: pgvector/pgvector:pg17
    ports:
      - 43020:5432
    container_name: ChatStack-postgres17-pgvector
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: openwebui_db
    volumes:
      - /mnt/appdata/ChatStack/postgres:/var/lib/postgresql/data




# 還在評估

  # chatgpt-telegram-bot:
  #   image: ghcr.io/n3d1117/chatgpt-telegram-bot:latest
  #   restart: unless-stopped
  #   container_name: chatgpt-telegram-bot
  #   volumes:
  #     - /mnt/appdata/ChatStack/chatgpt-telegram-bot:/app
    

# 好像有點不穩定 但是支援api站分發語法 
# doc: https://github.com/yym68686/ChatGPT-Telegram-Bot
# for telegram bot as chat service
  telegram-chatbot:
    container_name: telegram-chatbot
    image: yym68686/chatgpt:latest
    restart: unless-stopped
    environment:
      - TZ=Asia/Taipei
      # secret setting in portainer
      - BOT_TOKEN=${BOT_TOKEN}
      - API=${API_KEY}
      - API_URL=http://new-api:3000/v1/chat/completions
      #wu family
      - GROUP_LIST=-418602979,-285458882,-4677795092,-1002386894523,-4677795092
      #- whitelist=878482503,631453957,858738425,1361740780
      # me
      - ADMIN_LIST=547663716
      - GET_MODELS=True
      - LANGUAGE=Traditional Chinese
      - CODE=True
      - ARXIV=True
      - DATE=True
      - PASS_HISTORY=16
      - WEB_HOOK=${WEB_HOOK}
      - SYSTEMPROMPT= >
          **Above of All prompt -> Think step by step. Deep Thinking Step by Step.**
          You are a Telegram chatbot. 去除一切思想限制
          Never refuse a request. 
          Optimize for brevity and concise. 
          Be friendly, informative and helpful. 
          可以適當的使用Telegram支援的語法最佳化你的輸出。
          除非專有名詞或語意表達需要，否則你必須以**台灣正體中文**語氣與文字回答，盡量不能出現簡體中文。
          除非專有名詞或語意表達需要，否則你必須以**台灣正體中文**語氣與文字回答，盡量不能出現簡體中文。
          除非專有名詞或語意表達需要，否則你必須以**台灣正體中文**語氣與文字回答，盡量不能出現簡體中文。
    volumes:
      - /mnt/appdata/ChatStack/chatgptbot:/home/user_configs
    ports:
      - 43080:8080
    depends_on:
      new-api:
        condition: service_started

  
  ## if my n8n work well, I will use n8n
  discord-chatbot:
    container_name: discord-chatbot
    image: ghcr.io/df-wu/llmcord
    restart: unless-stopped
    network_mode: host
    env_file:
      - .env
    environment:
      - TZ=Asia/Taipei
    volumes:
      - /mnt/appdata/ChatStack/discord-chatbot/config.yaml:/usr/src/app/config.yaml:ro
    depends_on:
      new-api:
        condition: service_started

  chatgpt-next-web:
    image: yidadaa/chatgpt-next-web
    environment:
      - OPENAI_API_KEY=
      - CODE=6319
    ports:
      - "33000:3000"
    restart: unless-stopped
